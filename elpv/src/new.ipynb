{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.classifier import *\n",
    "from utils.dataloader import *\n",
    "from utils.features import *\n",
    "from utils.helper import *\n",
    "from utils.processing import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/moooooo16/Documents/Computer Vision/Project/elpv\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 66\n",
    "ROOT_PATH, DATA_PATH, OUT_PATH = get_paths()\n",
    "PARAMS = []\n",
    "NUMB_LAEBLS = 8\n",
    "L= 15\n",
    "print(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7] [588 117  56 313 920 178  50 402]\n",
      "(1968, 300, 300) (656, 300, 300)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "img_path, prob, types, labels= load_data(DATA_PATH, NUMB_LAEBLS)\n",
    "\n",
    "feature_builder = FeatureExtraction(DATA_PATH, img_path, labels, L)\n",
    "X_train, X_test, y_train, y_test = feature_builder.split_data(train_test_split, randome_state=RANDOM_STATE, stratify=True, split_ratio=0.25)\n",
    "# X_train, X_val, y_train, y_val = feature_builder.split_data(train_test_split, randome_state=RANDOM_STATE, stratify=True, split_ratio=0.1)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score, balanced_accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "preprocess_pipeline = [\n",
    "    # (strech_img, {\n",
    "    #     }),\n",
    "    # (clach_img, {\n",
    "    #     'clipLimit': 2.0,\n",
    "    #     'tileGridSize': (8, 8)}),\n",
    "    # (guassian_blur, {\n",
    "    #     'kernel_size': (0, 0),\n",
    "    #     'sigmaX': 3}),\n",
    "    # (lap_feature, {\n",
    "    #     'dst': -1,\n",
    "    #     'ksize' : 5}),\n",
    "    # (morpo_opening, {\n",
    "    #     'kernel': np.ones((2,2), np.uint8),\n",
    "    #     'iterations': 1}),\n",
    "    (morph_smoothing, {\n",
    "        'ses' : feature_builder.ses})\n",
    "]\n",
    "\n",
    "svm_param = {\n",
    "    'C': 10,\n",
    "    'kernel' : 'rbf',\n",
    "    # 'gamma' : 0.0001,\n",
    "    # 'class_weight' : 'balanced',\n",
    "    # 'verbose' : False,\n",
    "}\n",
    "\n",
    "grid_svm_params = {\n",
    "    'estimator': SVC,\n",
    "    'model_params': {\n",
    "        'kernel': ['rbf', 'linear', 'poly'],\n",
    "        'C' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'class_weight': ['balanced']},\n",
    "    'scoring': {\n",
    "        \"F1_Weighted\": make_scorer(f1_score, average='weighted'),\n",
    "        \"Balanced_Accuracy\": make_scorer(balanced_accuracy_score),},\n",
    "    'refit': 'Balanced_Accuracy',\n",
    "    'verbose' : 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_prepro = feature_builder.preprocess(X_train, preprocess_pipeline = preprocess_pipeline)\n",
    "# X_test_prepro = feature_builder.preprocess(X_test, preprocess_pipeline = preprocess_pipeline)\n",
    "\n",
    "# with open(os.path.join(OUT_PATH ,'X_prepro.pkl'), 'wb') as f:\n",
    "#     pickle.dump((X_train_prepro, X_test_prepro), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepro,  X_test_prepro = None, None\n",
    "\n",
    "with open(os.path.join(OUT_PATH ,'X_prepro.pkl'), 'rb') as f:\n",
    "    X_train_prepro, X_test_prepro = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/torch/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py:542: FutureWarning: Starting in v1.3, whiten='unit-variance' will be used by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/moooooo16/Documents/Computer Vision/project/elpv/src/new.ipynb Cell 7\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/moooooo16/Documents/Computer%20Vision/project/elpv/src/new.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m non_defecet_y \u001b[39m=\u001b[39m y_train[indices]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/moooooo16/Documents/Computer%20Vision/project/elpv/src/new.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ica \u001b[39m=\u001b[39m FastICA(random_state\u001b[39m=\u001b[39mRANDOM_STATE)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/moooooo16/Documents/Computer%20Vision/project/elpv/src/new.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m U \u001b[39m=\u001b[39m ica\u001b[39m.\u001b[39mfit_transform(X_train_prepro\u001b[39m.\u001b[39mreshape(X_train_prepro\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/moooooo16/Documents/Computer%20Vision/project/elpv/src/new.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(U\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py:708\u001b[0m, in \u001b[0;36mFastICA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model and recover the sources from X.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \n\u001b[1;32m    691\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39m    estimated unmixing matrix.\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 708\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_transform(X, compute_sources\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py:654\u001b[0m, in \u001b[0;36mFastICA._fit_transform\u001b[0;34m(self, X, compute_sources)\u001b[0m\n\u001b[1;32m    645\u001b[0m kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    646\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtol\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol,\n\u001b[1;32m    647\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mg\u001b[39m\u001b[39m\"\u001b[39m: g,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mw_init\u001b[39m\u001b[39m\"\u001b[39m: w_init,\n\u001b[1;32m    651\u001b[0m }\n\u001b[1;32m    653\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mparallel\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 654\u001b[0m     W, n_iter \u001b[39m=\u001b[39m _ica_par(X1, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    655\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdeflation\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    656\u001b[0m     W, n_iter \u001b[39m=\u001b[39m _ica_def(X1, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py:113\u001b[0m, in \u001b[0;36m_ica_par\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mfor\u001b[39;00m ii \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iter):\n\u001b[1;32m    112\u001b[0m     gwtx, g_wtx \u001b[39m=\u001b[39m g(np\u001b[39m.\u001b[39mdot(W, X), fun_args)\n\u001b[0;32m--> 113\u001b[0m     W1 \u001b[39m=\u001b[39m _sym_decorrelation(np\u001b[39m.\u001b[39mdot(gwtx, X\u001b[39m.\u001b[39mT) \u001b[39m/\u001b[39m p_ \u001b[39m-\u001b[39m g_wtx[:, np\u001b[39m.\u001b[39mnewaxis] \u001b[39m*\u001b[39m W)\n\u001b[1;32m    114\u001b[0m     \u001b[39mdel\u001b[39;00m gwtx, g_wtx\n\u001b[1;32m    115\u001b[0m     \u001b[39m# builtin max, abs are faster than numpy counter parts.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[39m# np.einsum allows having the lowest memory footprint.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# It is faster than np.diag(np.dot(W1, W.T)).\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py:64\u001b[0m, in \u001b[0;36m_sym_decorrelation\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     60\u001b[0m s \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mclip(s, a_min\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfinfo(W\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39mtiny, a_max\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     62\u001b[0m \u001b[39m# u (resp. s) contains the eigenvectors (resp. square roots of\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m# the eigenvalues) of W * W.T\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mmulti_dot([u \u001b[39m*\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msqrt(s)), u\u001b[39m.\u001b[39mT, W])\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch/lib/python3.11/site-packages/numpy/linalg/linalg.py:2750\u001b[0m, in \u001b[0;36mmulti_dot\u001b[0;34m(arrays, out)\u001b[0m\n\u001b[1;32m   2748\u001b[0m \u001b[39m# _multi_dot_three is much faster than _multi_dot_matrix_chain_order\u001b[39;00m\n\u001b[1;32m   2749\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m-> 2750\u001b[0m     result \u001b[39m=\u001b[39m _multi_dot_three(arrays[\u001b[39m0\u001b[39m], arrays[\u001b[39m1\u001b[39m], arrays[\u001b[39m2\u001b[39m], out\u001b[39m=\u001b[39mout)\n\u001b[1;32m   2751\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2752\u001b[0m     order \u001b[39m=\u001b[39m _multi_dot_matrix_chain_order(arrays)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch/lib/python3.11/site-packages/numpy/linalg/linalg.py:2782\u001b[0m, in \u001b[0;36m_multi_dot_three\u001b[0;34m(A, B, C, out)\u001b[0m\n\u001b[1;32m   2780\u001b[0m     \u001b[39mreturn\u001b[39;00m dot(dot(A, B), C, out\u001b[39m=\u001b[39mout)\n\u001b[1;32m   2781\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2782\u001b[0m     \u001b[39mreturn\u001b[39;00m dot(A, dot(B, C), out\u001b[39m=\u001b[39mout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "indices = np.where((y_train == 0) | (y_train == 4))[0]\n",
    "\n",
    "non_defecet_X = X_train_prepro[indices]\n",
    "non_defecet_y = y_train[indices]\n",
    "\n",
    "ica = FastICA(random_state=RANDOM_STATE)\n",
    "U = ica.fit_transform(X_train_prepro.reshape(X_train_prepro.shape[0], -1)) \n",
    "print(U.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1968,90000) and (100,1968) not aligned: 90000 (dim 1) != 100 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/moooooo16/Documents/Computer Vision/project/elpv/src/new.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/moooooo16/Documents/Computer%20Vision/project/elpv/src/new.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m U_plus \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mpinv(U)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/moooooo16/Documents/Computer%20Vision/project/elpv/src/new.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m b_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(X_train_prepro\u001b[39m.\u001b[39mreshape(X_train_prepro\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), U_plus)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/moooooo16/Documents/Computer%20Vision/project/elpv/src/new.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m b_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(X_test_prepro\u001b[39m.\u001b[39mreshape(X_test_prepro\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), U_plus)\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1968,90000) and (100,1968) not aligned: 90000 (dim 1) != 100 (dim 0)"
     ]
    }
   ],
   "source": [
    "U_plus = np.linalg.pinv(U)\n",
    "\n",
    "b_train = np.dot(X_train_prepro.reshape(X_train_prepro.shape[0], -1), U_plus)\n",
    "b_test = np.dot(X_test_prepro.reshape(X_test_prepro.shape[0], -1), U_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, clf = grid_search(b_train, y_train, **grid_svm_params)\n",
    "pred = clf.predict(b_test)\n",
    "\n",
    "acc, conf_mat = get_report(y_test, pred)\n",
    "\n",
    "print()\n",
    "print(f'Overall Test Accuracy: {acc:.2f}')\n",
    "print(f'Confusion Matrix: \\n{conf_mat}')\n",
    "print('-'*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
